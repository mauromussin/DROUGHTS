{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e10c789",
   "metadata": {},
   "source": [
    "# Agricultural Drought Risk Assessment\n",
    "<br>\n",
    "\n",
    "Click [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CLIMAAX/DROUGHTS/HEAD?labpath=02_agriculture_drought%2FAGRICULTURE_DROUGHT_Risk_Assessment.ipynb) to launch the workflow on Binder!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8121c9",
   "metadata": {},
   "source": [
    "In this workflow we will visualise the revenue losses deriving from the reduction in crops yield due to precipitation scarcity and  absence of irrigation. This assessment is particularly relevant for semi-arid regions (e.g., Mediterranean) which are increasingly prone to  prolonged drought periods making artificial irrigation unfeasible at times, as well as historically wet regions (e.g., Central and Northern Europe) that have not yet implemented artificial irrigation at large-scale but might experience a significant decline in precipitation rates with future climate change. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d37f98a",
   "metadata": {},
   "source": [
    "## Risk Assessment methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc44d784",
   "metadata": {},
   "source": [
    "The risk assessment methodology is described in detail in the [description](AGRICULTURE_Risk_workflow_description.md) file. In summary, data on  total crop production [ton] and revenue [EUR] is combined with the yield loss reduction calculated in the [hazard](AGRICULTURE_DROUGHT_Hazard.ipynb) workflow to derive a map of the revenue loss from absence of irrigation. Revenue loss is expressed here as the 'lost opportunity cost' of not using irrigation. The maps also shows the distribution of existing irrigation systems, which are used as a proxy of vulnerability to precipitation scarcity. The assessment is currently available for the same 14 crops available for the hazard assessment, but the selection can be expanded by modifying the [crop table](crop_table.csv). \n",
    "\n",
    "### Limitations\n",
    "The main limitation of this approach is the fact that the crop production, aggregated value and irrigation distribution datasets refer to 2010 values and might not be accurately representative of current conditions. The user is invited to replace these datasets with more updated information whenever possible. The limitations of the yield loss calculation procedure are discussed in the [hazard](AGRICULTURE_DROUGHT_Hazard.ipynb) workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1a448",
   "metadata": {},
   "source": [
    "## Load libraries\n",
    "In this notebook we will use the following Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c903b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import pooch\n",
    "import json\n",
    "import urllib\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from pyDataverse.api import NativeApi, DataAccessApi\n",
    "from pyDataverse.models import Dataverse\n",
    "from mpl_toolkits.basemap import maskoceans\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ed331b-6843-46ca-b255-1f229abe6874",
   "metadata": {},
   "source": [
    ":::{admonition}\n",
    ":class: hint dropdown\n",
    "- [numpy](https://numpy.org/doc/stable/index.html) - To make calculations and handle data in the form of arrays.\n",
    "- [pandas](https://pandas.pydata.org/docs/index.html) - To store data in the form of DataFrames.\n",
    "- [geopandas](https://geopandas.org/en/stable/index.html) - To read georeferenced files as DataFrames.\n",
    "- [zipfile](https://docs.python.org/3/library/zipfile.html) - To extract files from zipped folders.\n",
    "- [os](https://docs.python.org/3/library/os.html) - To create directories and work with files\n",
    "- [pooch](https://www.fatiando.org/pooch/latest/index.html) - To download data from various repositories.\n",
    "- [pyDataverse](https://pydataverse.readthedocs.io/en/latest/) - To download data from Harvard Dataverse. \n",
    "- [rasterio](https://rasterio.readthedocs.io/en/stable/) - To access and explore geospatial raster data in GeoTIFF format.\n",
    "- [matplotlib](https://matplotlib.org/) and [Basemap](https://matplotlib.org/basemap/stable/)  - For plotting.\n",
    "- [re](https://docs.python.org/3/library/re.html) - To rename files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff4867f",
   "metadata": {},
   "source": [
    "## Create the directory structure\n",
    "First, we need to set up the directory structure to make the workflow work.\n",
    "The next cell will create the directory called 'agriculture_workflow' in the same directory where this notebook is saved. A directory for data and one for results will also be created inside the main workflow directory to store the downloaded data and the final plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2153ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_dir = 'agriculture_workflow'\n",
    "\n",
    "# Define directories for data and results within the previously defined workflow directory\n",
    "data_dir = os.path.join(workflow_dir, 'data')\n",
    "results_dir = os.path.join(workflow_dir, 'results')\n",
    "\n",
    "# Check if the workflow directory exists, if not, create it along with subdirectories for data and results\n",
    "if not os.path.exists(workflow_dir):\n",
    "    os.makedirs(workflow_dir)\n",
    "    os.makedirs(data_dir)\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e18afe0",
   "metadata": {},
   "source": [
    "## Define the studied area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61620a",
   "metadata": {},
   "source": [
    "\n",
    "The cells below allows to download the boundaries of any NUTS2 region in the EU as a GeoJson file given the region code (in this case ES51 for Catalunya). You can look up the NUTS2 code for all EU regions [here](https://ec.europa.eu/eurostat/documents/3859598/15193590/KS-GQ-22-010-EN-N.pdf) by simply searching the document for the region name. \n",
    "\n",
    "The coordinates of the selected regions are extracted and saved in an array. Finally, the geometry of the GeoJson file is saved as a shapefile to be used in the plotting phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fa4fed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = ['ES51'] #Replace the code in [''] with that of your region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b7f954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#auxiliary function to load region GeoJson file.\n",
    "def load_nuts_json(json_path):\n",
    "    # dependencies: json, urllib, geopandas, \n",
    "    while True:\n",
    "        uh = urllib.request.urlopen(json_path)\n",
    "        data = uh.read()\n",
    "        break  \n",
    "    gdf = gpd.GeoDataFrame.from_features(json.loads(data)[\"features\"])\n",
    "    gdf['Location'] = gdf['CNTR_CODE'] \n",
    "    gdf = gdf.set_index('Location')\n",
    "    #gdf.to_crs(pyproj.CRS.from_epsg(4326), inplace=True)\n",
    "    return gdf\n",
    "\n",
    "# load nuts2 spatial data\n",
    "json_nuts_path = 'https://gisco-services.ec.europa.eu/distribution/v2/nuts/geojson/NUTS_RG_10M_2021_4326_LEVL_2.geojson'\n",
    "nuts = load_nuts_json(json_nuts_path)\n",
    "nuts = nuts.loc[nuts['NUTS_ID'].isin(region)]\n",
    "\n",
    "#extract coordinates\n",
    "df=gpd.GeoSeries.get_coordinates(nuts)\n",
    "coords_user=df.to_numpy()\n",
    "\n",
    "#save geometry as shapefile\n",
    "nuts_name=re.sub(r'[^a-zA-Z0-9]','',str(nuts.iloc[0,4]))\n",
    "nuts_shape=nuts.geometry.explode(index_parts=True).to_file(f'{data_dir}/{nuts_name}.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af09704a-c0e2-47d3-9c52-5746b5e06df7",
   "metadata": {},
   "source": [
    "The code below creates the study area bounding box using the coordinates of the region GeoJson file. \n",
    "\n",
    "In some cases, it might be needed to expand the selected area through the 'scale' parameter to avoid the corners of the region being left out from the data extraction. The units of the 'scale' parameter are degrees, so setting scale=1 will increase the extraction area by approximately 100 km. A scale of 0-0.5 should be sufficient to fully cover most regions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e46364-947a-480c-a4d0-bac5a85a73bb",
   "metadata": {},
   "source": [
    ":::{warning} The larger the scale parameter, the larger the extracted area, the longer the workflow will run for. Thus, the user is invited to have a first run of the workflow with scale=0.5, then increase it if not satisfied with the data coverage of the final map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca2985-0a78-4ea1-9535-d4ba93c64c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the region bounding box, scale parameter can be adjusted \n",
    "scale=0.5\n",
    "bbox=[np.min(coords_user[:,0])-scale,np.min(coords_user[:,1])-scale,np.max(coords_user[:,0])+scale,np.max(coords_user[:,1])+scale]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea319a",
   "metadata": {},
   "source": [
    "## Import hazard data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ed510d",
   "metadata": {},
   "source": [
    "To run the risk assessment workflow you will first need to import data from the [hazard](AGRICULTURE_DROUGHT_Hazard.ipynb) workflow. If you have already run the hazard workflow you can ignore the cell below. If you have not, cancel the '#' in the cell below to activate the code and run it to start the hazard workflow creating the files needed for the risk assessment. This might take a few minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778be639",
   "metadata": {},
   "source": [
    "::: {warning} The hazard assessment workflow uses Catalunya as a default region. If you want to run the risk workflow for a different region, change the selection in the [hazard](AGRICULTURE_DROUGHT_Hazard.ipynb) workflow first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9370ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run AGRICULTURE_DROUGHT_Hazard.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f81f3",
   "metadata": {},
   "source": [
    "Run the cell below to load data from the hazard assessment and visualise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load yield loss data from the .npy and .csv files produced by the hazard workflow\n",
    "yield_loss_perc=np.load(f'{results_dir}/'+str(nuts.iloc[0,4])+'_yield_loss_NUMPY.npy')\n",
    "hazard_df=pd.read_csv(f'{results_dir}/'+str(nuts.iloc[0,4])+'_yield_loss_SPREADSHEET.csv')\n",
    "\n",
    "\n",
    "#visualise the yield loss maps produced by the hazard workflow\n",
    "\n",
    "hazard_files = list(filter(lambda x: nuts.iloc[0,4] in x and 'yield_loss.png' in x, os.listdir(results_dir)))\n",
    "\n",
    "for i in hazard_files:\n",
    "    img = mpimg.imread(f'{results_dir}/{i}',format='png')\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_axes([0, 0, 1, 1])\n",
    "    ax.set_axis_off()\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3de268",
   "metadata": {},
   "source": [
    "## Download and extract Exposure data\n",
    "### 1. Crops Production  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7464f629",
   "metadata": {},
   "source": [
    "Next we will need data on crop production to calculate exposure. Crop production [ton] data for 2010 is retrieved from the [MapSPAM](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/PRFF8V) repository on Harvard Dataverse. Data is available as global .tif rasters at 5 arc-min resolution for different combinations of human inputs and irrigation modes. In this assessment, we will use data for crops grown under 'high' human inputs and 'all' irrigation modes. 42 files are downloaded, one for each crop available on the MapSPAM repository. The step-by-step download procedure is explained within the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1dd190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify path where the final zip file will be saved\n",
    "spam_path=f'{data_dir}/spam_prod_geotiff.zip'\n",
    "\n",
    "#create a folder in the data directory where all the SPAM files are extracted\n",
    "if not os.path.exists(f'{data_dir}/spam_folder'):\n",
    "    os.mkdir(f'{data_dir}/spam_folder')\n",
    "\n",
    "#setting up the API to retrieve the SPAM dataset from Harvard Dataverse given the DOI. \n",
    "base_url = 'https://dataverse.harvard.edu/'\n",
    "api = NativeApi(base_url)\n",
    "data_api = DataAccessApi(base_url)\n",
    "DOI='doi:10.7910/DVN/PRFF8V' \n",
    "dataset = api.get_dataset(DOI)\n",
    "files_list = dataset.json()['data']['latestVersion']['files']\n",
    "\n",
    "#download the dataset for crops production given the ID\n",
    "download_id='3985009'\n",
    "response = data_api.get_datafile(download_id,is_pid=False)\n",
    "with open(spam_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "\n",
    "#extract the necessary SPAM files in the spam_folder,this selects the 'all' irrigation files only\n",
    "with zipfile.ZipFile(spam_path, 'r') as zObject:\n",
    "    file_list=zObject.namelist()\n",
    "    selected_files = list(filter(lambda x: '_A.tif' in x, file_list))\n",
    "    zObject.extractall(path=f'{data_dir}/spam_folder',members=selected_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb0675d",
   "metadata": {},
   "source": [
    ":::{tip} You might be interested in other files in the SPAM directory other than the production ones used in this workflow. Run the cell below to print all the files in the SPAM repository and find the ID code needed to download them. In this workflow we are using the 'spam2010v2r0_global_prod.geotiff.zip' file and associated download id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = dataset.json()['data']['latestVersion']['files']\n",
    "for file in files_list:\n",
    "    filename = file[\"dataFile\"][\"filename\"]\n",
    "    file_id = file[\"dataFile\"][\"id\"]\n",
    "    print(\"File name {}, id {}\".format(filename, file_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25399d18",
   "metadata": {},
   "source": [
    "To select the SPAM files for the crops you are interested in, you will have to correctly specify their name. Run the cell below to print the list of available crops. In the SPAM files, crops are identified by a 4-letter acronym in capital letters. For instance, Arabica Coffee is ACOF, cotton is COTT ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f181e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a29be",
   "metadata": {},
   "source": [
    "Now copy the acronym of the crops you want to study in the cell below and run it. In this example, we are interested in wheat and maize. **Remember** you can only get results for the 14 crops parameterised in the [crop table](crop_table.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746926b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_list=['MAIZ','WHEA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e3d60",
   "metadata": {},
   "source": [
    "The cell below extracts data from the SPAM files, first for the studied crops then for all available crops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6af41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the extraction coordinates from the hazard dataframe\n",
    "coords_11=np.stack((hazard_df['lon'].to_numpy(),hazard_df['lat'].to_numpy()),axis=1)\n",
    "\n",
    "#extraxction of studied crops production \n",
    "df_spam=pd.DataFrame()\n",
    "for i in os.listdir(f'{data_dir}/spam_folder'):\n",
    "    for a in np.arange(len(spam_list)):\n",
    "        if spam_list[a] in i:\n",
    "            raster_path = os.path.join(f'{data_dir}/spam_folder', i)\n",
    "            with rasterio.open(raster_path) as src:\n",
    "                values = [x[0] for x in src.sample(coords_11)]\n",
    "            # Create a new column for each raster\n",
    "            df_spam[spam_list[a]] = values\n",
    "\n",
    "crops_spam=df_spam.to_numpy(dtype='float64')\n",
    "crops_spam[crops_spam<0]=np.nan\n",
    "crops_spam=crops_spam.reshape(len(yield_loss_perc[:,0,0]),len(yield_loss_perc[0,:,0]),len(spam_list))\n",
    "\n",
    "#extraction of all crops production\n",
    "df_spam_all=pd.DataFrame()\n",
    "for i in os.listdir(f'{data_dir}/spam_folder'):\n",
    "    raster_path = os.path.join(f'{data_dir}/spam_folder', i)\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        values = [x[0] for x in src.sample(coords_11)]\n",
    "\n",
    "    # Create a new column for each raster\n",
    "    df_spam_all[i] = values\n",
    "\n",
    "df_spam_sum=df_spam_all.sum(axis=1)\n",
    "spam_sum=df_spam_sum.to_numpy(dtype='float64')\n",
    "spam_sum[spam_sum<0]=np.nan\n",
    "spam_sum=spam_sum.reshape(len(yield_loss_perc[:,0,0]),len(yield_loss_perc[0,:,0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af79c1c6",
   "metadata": {},
   "source": [
    "### 2. Crops Aggregated Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec1ee2",
   "metadata": {},
   "source": [
    "The second exposure dataset we need is about crops aggregated value. Data is sourced from the FAO Global Agro-Ecological Zones (GAEZ) data [portal](https://gaez.fao.org/). Data is available as global .tif rasters at 11 km resolution showing the aggregated crops value in 2010 international dollars (GK$), having the same purchasing power of US dollars (USD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2360ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://s3.eu-west-1.amazonaws.com/data.gaezdev.aws.fao.org/res06/V/2010/all_2010_val.tif'\n",
    "filename = 'all_2010_val.tif'\n",
    "pooch.retrieve(\n",
    "    url=url,fname=filename,\n",
    "    known_hash='ae8f7a3532912dbee24efbb83a5df0ca2685bc65c30fcdca6212fe72eba13d6e',\n",
    "    path=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4438c646",
   "metadata": {},
   "source": [
    "The cell below extracts aggregated value data from the raster and stores them as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a954b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract values\n",
    "raster_path = f'{data_dir}/all_2010_val.tif'\n",
    "val_gaez=pd.DataFrame()\n",
    "with rasterio.open(raster_path) as src:\n",
    "    values = [x[0] for x in src.sample (coords_11)]\n",
    "val_gaez['val']=values\n",
    "val_gaez=val_gaez.to_numpy(dtype='float64')\n",
    "val_gaez[val_gaez<0]=np.nan\n",
    "val_gaez=val_gaez.reshape(len(yield_loss_perc[:,0,0]),len(yield_loss_perc[0,:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a967298",
   "metadata": {},
   "source": [
    "## Download and extract Vulnerability data - Irrigation availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b86e2a2",
   "metadata": {},
   "source": [
    "Next we will need data on cropland full-irrigation availability to define vulnerability. This dataset is also sourced from GAEZ and is available at the same resolution as the aggregated value data. The dataset shows the percentage of cropland in each grid-cell equipped with irrigation systems.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://s3.eu-west-1.amazonaws.com/data.gaezdev.aws.fao.org/LR/wat/GLCSv11_12_5m.tif'\n",
    "filename = 'GLCSv11_12_5m.tif'\n",
    "pooch.retrieve(\n",
    "    url=url,fname=filename,\n",
    "    known_hash='798437a7c5bfa5887c5dd9eacb42b7388db9e4f3073b3c8d4cf4e5d6c9bcedb7',\n",
    "    path=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4199a694",
   "metadata": {},
   "source": [
    "The cell below extracts irrigation availability data from the raster and stores them as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff774da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract irrigation availability data\n",
    "raster_path = f'{data_dir}/GLCSv11_12_5m.tif'\n",
    "irr_share=pd.DataFrame()\n",
    "with rasterio.open(raster_path) as src:\n",
    "    values = [x[0] for x in src.sample(coords_11)]\n",
    "irr_share['irr']=values\n",
    "irr_share=irr_share.to_numpy(dtype='float64')\n",
    "irr_share[irr_share==0]=0.1\n",
    "irr_share=irr_share.reshape(len(yield_loss_perc[:,0,0]),len(yield_loss_perc[0,:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f01e352",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458028d8",
   "metadata": {},
   "source": [
    "The first step in the risk assessment calculation entails defining the share of total crop production represented by the studied crops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f66d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the fraction of total production represented by the studied crops\n",
    "crop_prod_fraction=np.zeros((len(yield_loss_perc[:,0,0]),len(yield_loss_perc[0,:,0]),len(spam_list)))\n",
    "for i in np.arange(len(spam_list)):\n",
    "    crop_prod_fraction[:,:,i]=crops_spam[:,:,i]/spam_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c65ed",
   "metadata": {},
   "source": [
    "Next, we will need to determine the economic value per pixel of the studied crops. To do so, we will: \n",
    "1. Calculate the revenue per ton of the total crop production (USD/ton total)\n",
    "2. Multiply the total revenue per ton for the studied crops fraction to get the value per ton for the studied crops (USD/ton studied) \n",
    "3. Multiply the studied crops revenue per ton for their production to get the revenue in each grid cell originating from the studied crops (USD/grid-cell)\n",
    "4. Multiply the revenue per grid-cell for the yield loss calculated in the hazard workflow we will get the reduced revenue due to absence of irrigation (USD/grid-cell)\n",
    "5. Finally, convert the results from USD to EUR using the 2010 average exchange rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109f32ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty arrays to store info\n",
    "rev_per_ton_tot=np.zeros((len(yield_loss_perc[:,0,0]),len(yield_loss_perc[0,:,0]),len(spam_list)))\n",
    "rev_per_ton_crop=np.zeros((len(yield_loss_perc[:,0,0]),len(yield_loss_perc[0,:,0]),len(spam_list)))\n",
    "rev_per_pixel_crop=np.zeros((len(yield_loss_perc[:,0,0]),len(yield_loss_perc[0,:,0]),len(spam_list)))\n",
    "new_rev_per_pixel_crop=np.zeros((len(yield_loss_perc[:,0,0]),len(yield_loss_perc[0,:,0]),len(spam_list)))\n",
    "\n",
    "\n",
    "for a in np.arange(len(spam_list)):\n",
    "    #step 1: total revenue per ton\n",
    "    rev_per_ton_tot=val_gaez/spam_sum\n",
    "    #step 2: studied crops revenue per ton\n",
    "    rev_per_ton_crop[:,:,a]=rev_per_ton_tot*crop_prod_fraction[:,:,a]\n",
    "    #step 3: studied crops revenue per grid-cell\n",
    "    rev_per_pixel_crop[:,:,a]=rev_per_ton_crop[:,:,a]*crops_spam[:,:,a]\n",
    "    #step 4: studied crops revenue per grid-cell without irrigation\n",
    "    new_rev_per_pixel_crop[:,:,a]=rev_per_ton_crop[:,:,a]*crops_spam[:,:,a]*yield_loss_perc[:,:,a]/100\n",
    "\n",
    "\n",
    "#calculate the revenue loss as the difference between step 3 and step 4    \n",
    "revenue_loss=rev_per_pixel_crop-new_rev_per_pixel_crop\n",
    "\n",
    "#convert from USD to EUR at 2010 exchange rate\n",
    "reveune_loss_euro=revenue_loss/1.3    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51a4b68",
   "metadata": {},
   "source": [
    "## Plotting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b0b1ec",
   "metadata": {},
   "source": [
    "The cell below allows to plot the revenue loss results for the studied region. The red shading shows the revenue loss per grid-cell for the studied crops deriving from the absence of irrigation. The hatching shows different levels of irrigation infrastructure availability within the region, highlighting areas of different vulnerability.\n",
    "\n",
    "The resulting plot states the crop, RCP scenario and reference period used in the assessment. The plotting procedure steps are described within the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be336587",
   "metadata": {},
   "source": [
    ":::{tip} Use the 'zoom' paramerter to set how much you would like the final plot to be zoomed-out from the region boundaries (0=no zoom out,1=100 km). Here a zoom of 0.5 degrees (50 km) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b94d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rcp=hazard_df['rcp'][0] #identify the climate projection\n",
    "ystart=hazard_df['start_year'][0] #identify the projection start year\n",
    "yend=hazard_df['end_year'][0] #identify the projection end year\n",
    "\n",
    "#zoom parameter\n",
    "zoom=0.5 \n",
    "\n",
    "#define the longitude and latitude coordinates\n",
    "lon_plot=hazard_df['lon'].to_numpy().reshape(len(yield_loss_perc[:,0,0]),len(yield_loss_perc[0,:,0]))\n",
    "lat_plot=hazard_df['lat'][:].to_numpy().reshape(len(yield_loss_perc[:,0,0]),len(yield_loss_perc[0,:,0]))\n",
    "\n",
    "#define the irrigation vulnerability levels\n",
    "irr_levels=np.array([0,10,30,75,100])\n",
    "irr_share_plot=maskoceans(lon_plot,lat_plot,irr_share,resolution='h')\n",
    "\n",
    "for a in np.arange(len(spam_list)):\n",
    "    #create the basemap around the region boundaries\n",
    "    basemap =Basemap(\n",
    "               resolution='i',\n",
    "               llcrnrlat=bbox[1]-zoom, urcrnrlat=bbox[3]+zoom,\n",
    "               llcrnrlon=bbox[0]-zoom, urcrnrlon=bbox[2]+zoom,\n",
    "               lon_0=bbox[1],lat_0=bbox[0])\n",
    "    basemap.drawcoastlines()\n",
    "    basemap.drawcountries()\n",
    "    \n",
    "    #plot the revenue loss\n",
    "    revenue_map=basemap.contourf(lon_plot,lat_plot,revenue_loss[:,:,a],cmap='Reds',zorder=1)\n",
    "    revenue_cbar=basemap.colorbar(revenue_map,location='left',ticklocation='left')\n",
    "    revenue_cbar.set_label('Revenue loss without irrigation (1000 EUR)',fontsize=12)\n",
    "   \n",
    "    #plot the irrigation availability\n",
    "    irr_map=basemap.contourf(lon_plot,lat_plot,irr_share_plot,colors='none',hatches=['','..','xx','O'],zorder=1,levels=irr_levels)\n",
    "    irr_cbar=basemap.colorbar(irr_map)\n",
    "    irr_cbar.set_label('Share of cropland with irrigation (%)',fontsize=12)\n",
    "    \n",
    "    #draw region boundaries from shapefile\n",
    "    basemap.readshapefile(f'{data_dir}/{nuts_name}',nuts_name,color='b',linewidth=2) \n",
    "    \n",
    "    plt.suptitle(spam_list[a]+' revenue loss from precipitation deficit',fontsize=13,fontweight='bold') #title\n",
    "    plt.title(str(nuts.iloc[0,4])+' '+rcp+' '+str(ystart)+'-'+str(yend)) #subtitle\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    #save plots in results directory\n",
    "    plt.savefig(f'{results_dir}/'+str(nuts.iloc[0,4])+'_'+str(spam_list[a])+'_revenue_loss_EUR.png') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2847008b-106f-4817-8f2b-063e3649ccf5",
   "metadata": {},
   "source": [
    "The figures produced show the potential revenue losses from irrigation deficit in the studied region for the selected crops (here maize and wheat), emission scenario (here RCP2.6) and period (here 2046-2050). Losses are expressed by the red shading and represent the 'lost opportunity cost' in thousands euros if crops are grown under non-irrigated conditions. The hatches show the share of cropland in each grid-point with irrigation systems already implemented in 2010 and serves as an indicator of vulnerability to rainfall scarcity. \n",
    "<br>\n",
    "\n",
    "These maps can be used by demonstrators to understand which areas of their region are expected to suffer the greatest losses, as well as which crops will be the most impacted by the absence of irrigation. This allows them to target adaptation efforts, such as the improvement of the current irrigation network, in the most affected and vulnerable areas favouring a cost-effective use of resources. At the same time, the map provides a snap-shot of a potential future growing season that can be used to guide cropland expansion towards areas and products less affected by water stress.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca8a891-e1d3-498e-8602-6241c7c19d3f",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6962ef-5228-4018-805f-f485c1136137",
   "metadata": {},
   "source": [
    "Now that you were able to calculate damage maps based on yield loss maps and view the results, you can consider the following questions:\n",
    "\n",
    "- How accurate do you think this result is for your local context? \n",
    "- What additional information are you missing that could make this assessment more accurate?\n",
    "- What can you already learn from these maps of potential yield and revenue losses?\n",
    "\n",
    ":::{important}\n",
    "In this risk workflow we learned:\n",
    "\n",
    "- how to access and use global datasets on crop production and irrigation availability.\n",
    "- how to combine data on potential yield losses to the current crop production to estimate future potential revenue losses.\n",
    "- how to use maps of irrigation distribution as a proxy for water-stress vulnerability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba2f0d",
   "metadata": {},
   "source": [
    "## Contributors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df3b6ee",
   "metadata": {},
   "source": [
    "Euro-Mediterranean Center on Climate Change (CMCC), Italy.\n",
    "\n",
    "Author of the workflow: Andrea Rivosecchi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper_grano",
   "language": "python",
   "name": "paper_grano"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
