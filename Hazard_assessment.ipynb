{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114c11c0-af34-4523-92fb-9a0d62cd518b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hazard assessment for drought\n",
    "\n",
    "Click [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CLIMAAX/DROUGHTS/main?labpath=DROUGHTS_notebook_1.ipynb) to launch this workflow on MyBinder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd026bd",
   "metadata": {},
   "source": [
    "### Quantifying drought hazard\n",
    "\n",
    "Hazard indicators Drought hazard (dH) for a given region is estimated as the probability of exceedance of the median of regional (e.g., EU level) severe precipitation deficits for the historical reference period 1979 -2019.\n",
    "The precipitation deficit is calculated using the weighted anomaly of standardized precipitation (WASP) index. This index accounts for precipitation seasonal patterns and is computed by summing weighted and standardized monthly precipitation anomalies $^1$.\n",
    "\n",
    "We use the weighted anomaly of standardized precipitation (WASP) index to define the severity of precipitation deficit. The WASP-index takes into account the annual seasonality of the precipitation cycle and is computed by summing weighted standardized monthly precipitation anomalies (see Eq. 1). Where $P_{n,m}$ is each region's monthly precipitation, $T_m$ is a monthly treshold defining precipitation severity, and $T_A$ is an annual threshold for precipitation severity. The thresholds are defined by dividing multi-annual monthly observed rain using the 'Fisher-jenks' classigication algorithm $^2$. \n",
    "\n",
    "Eq. 1: $$WASP_j = \\Sigma_{P_{n,m} < T_m}^{P_{n,m} >= T_m}( \\frac{P_{n,m} - T_m}{T_m})*\\frac{T_m}{T_A}$$\n",
    "\n",
    "#### Hazard data and methods:\n",
    "\n",
    "This algorithm requires monthly total precipitation for each NUTS2 region during the historical reference period. Usually, these are observation-based or simulated time series of gridded precipitation data. Processing these data is performed by applying Geographic Information System (GIS) techniques, to extract an aggregated value (e.g., total precipitation) of the data points located within each area of interest (e.g., NUTS2 region). Zonal statistics is widely used for that purpose.\n",
    "\n",
    "Point, observation-based datasets are an alternative data source, usually collected by meteorological station networks. One can choose the data collected in one or more (e.g., average) representative stations per area of interest to construct a NUTS2 level dataset. The algorithm expects a table in which each row represnt a month-year combination, and each column an area of interest. The first column represnts the date following this format YYYY-MM-DD. The **title of the first columns has to be 'timing', and the rest of the titles has to be the codes of the areas of interest (e.g., NUTS2), which have to be identical to the codes as they appear in the NUTS2 spatial data from the [European Commision](https://ec.europa.eu/eurostat/en/web/nuts/background)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ccebc",
   "metadata": {},
   "source": [
    "# Workflow implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6c3e8",
   "metadata": {},
   "source": [
    "### Load libraries\n",
    "\n",
    "In this notebook we will use the following Python libraries:\n",
    "- [os](https://docs.python.org/3/library/os.html) - To create directories and work with files\n",
    "- [urllib](https://docs.python.org/3/library/urllib.html) - To access to online resources\n",
    "- [pandas](https://pandas.pydata.org/docs/user_guide/index.html) - To create and manage data frames (tables) in Python\n",
    "- [geopandas](https://geopandas.org/en/stable/docs.html) - Extend pandas to store and manipulate spatial data\n",
    "- [numpy](https://numpy.org/doc/stable/) - For basic math tools and operations\n",
    "- [scipy](https://scipy.org/) - Provide advanced mathematical tools and optimization capacities \n",
    "- [jenkspy](https://github.com/mthh/jenkspy) - To apply Fisher-Jenks alogrithm \n",
    "- [json](https://docs.python.org/3/library/json.html) - To load, store and manipuilate JSON objects\n",
    "- [pyproj](https://pyproj4.github.io/pyproj/stable/) - An interface to a geographic projections and transformations library\n",
    "- [matplotlib](https://matplotlib.org/) - For plotting\n",
    "- [plotly](https://plotly.com/python/) - For dynamic and interactive plotting\n",
    "- [datetime](https://docs.python.org/3/library/datetime.html) - For handling dates in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06a2286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "# lOAD LIBRARIES\n",
    "import os\n",
    "import urllib\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import jenkspy\n",
    "import json\n",
    "import pyproj\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Function for calculating drought hazard indices\n",
    "%run DROUGHTS_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b9ec1",
   "metadata": {},
   "source": [
    "### Define working environment and global parameters\n",
    "This workflow relies on pre-proceessed data. The user will define the path to the data folder and the code below would create a folder for outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ad5f46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\site-packages\\certifi\\cacert.pem\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m     h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m               encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\http\\client.py:1298\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\http\\client.py:1344\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1343\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\http\\client.py:1293\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\http\\client.py:1052\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1052\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1055\u001b[0m \n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\http\\client.py:990\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 990\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\http\\client.py:1470\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1468\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m-> 1470\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mwrap_socket(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock,\n\u001b[0;32m   1471\u001b[0m                                       server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname)\n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    512\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    514\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msslsocket_class\u001b[38;5;241m.\u001b[39m_create(\n\u001b[0;32m    518\u001b[0m         sock\u001b[38;5;241m=\u001b[39msock,\n\u001b[0;32m    519\u001b[0m         server_side\u001b[38;5;241m=\u001b[39mserver_side,\n\u001b[0;32m    520\u001b[0m         do_handshake_on_connect\u001b[38;5;241m=\u001b[39mdo_handshake_on_connect,\n\u001b[0;32m    521\u001b[0m         suppress_ragged_eofs\u001b[38;5;241m=\u001b[39msuppress_ragged_eofs,\n\u001b[0;32m    522\u001b[0m         server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[0;32m    523\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    524\u001b[0m         session\u001b[38;5;241m=\u001b[39msession\n\u001b[0;32m    525\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1103\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1104\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\ssl.py:1382\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1381\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1383\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# load nuts3 spatial data\u001b[39;00m\n\u001b[0;32m     27\u001b[0m json_nuts_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://gisco-services.ec.europa.eu/distribution/v2/nuts/geojson/NUTS_RG_01M_2021_4326_LEVL_3.geojson\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 28\u001b[0m nuts \u001b[38;5;241m=\u001b[39m load_nuts_json(json_nuts_path)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13496\\3995536437.py:9\u001b[0m, in \u001b[0;36mload_nuts_json\u001b[1;34m(json_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_nuts_json\u001b[39m(json_path):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# dependencies: json, urllib, geopandas, \u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 9\u001b[0m         uh \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(json_path)\n\u001b[0;32m     10\u001b[0m         data \u001b[38;5;241m=\u001b[39m uh\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m  \n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    537\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[0;32m   1392\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context, check_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_hostname)\n",
      "File \u001b[1;32mc:\\Users\\artuso\\AppData\\Local\\anaconda3\\envs\\climaxx\\Lib\\urllib\\request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)>"
     ]
    }
   ],
   "source": [
    "# Set Global Settings\n",
    "\n",
    "workflow_folder = 'H:/CLIMAXX/preprocessing/New-folder/NUTS3'\n",
    "# debug if folder does not exist - issue an error to check path\n",
    "\n",
    "# create outputs folder\n",
    "if not os.path.exists(os.path.join(workflow_folder, 'outputs')):\n",
    "    os.makedirs(os.path.join(workflow_folder, 'outputs'))\n",
    "\n",
    "# set country = 0 to map all Europe\n",
    "#country =  0\n",
    "\n",
    "# alternatively choose one country code (2-digits), e.g. 'IT' for Italy, or more than one to choose several country\n",
    "# e.g., run for North Macedonia and Greece, by setting country = ['MK', 'EL']\n",
    "country =  ['DE']\n",
    "\n",
    "# Filter countries/locations with missing data (e.g., Liechtenstein, Malta, ..), or very small/remote islands.\n",
    "filterNUTS = ['ES630', 'ES640']\n",
    "\n",
    "# Filter non-European countries (+ missing data): Turkey, England\n",
    "filterCNTS = ['UK', 'TR']\n",
    "\n",
    "import certifi\n",
    "print(certifi.where())\n",
    "\n",
    "# load nuts3 spatial data\n",
    "json_nuts_path = 'https://gisco-services.ec.europa.eu/distribution/v2/nuts/geojson/NUTS_RG_01M_2021_4326_LEVL_3.geojson'\n",
    "nuts = load_nuts_json(json_nuts_path)\n",
    "# nuts = nuts.query('NUTS_ID not in @filterNUTS')\n",
    "# nuts = nuts.query('CNTR_CODE not in @filterCNTS')\n",
    "# # Select poligons\n",
    "# if country == 0:\n",
    "#     regions = list(nuts['NUTS_ID'])\n",
    "# else:\n",
    "#     regions = list(nuts.loc[np.isin(nuts['CNTR_CODE'], country), ]['NUTS_ID'])\n",
    "\n",
    "# # define output table \n",
    "# nuts = nuts.loc[nuts['NUTS_ID'].isin(regions)]\n",
    "# output = pd.DataFrame(regions, columns = ['NUTS_ID'])\n",
    "# print('>>>>> NUTS3 map has loaded succefully.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eb7d4d",
   "metadata": {},
   "source": [
    "### Loading and visualize precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636f561d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing drought hazard. This process may take few minutes...\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'regions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m precip[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtiming\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(precip[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtiming\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#'%b-%Y'\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# column subset based on selected regions\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m col_subset \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misin(precip\u001b[38;5;241m.\u001b[39mcolumns, regions)\n\u001b[0;32m     11\u001b[0m col_subset[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \n\u001b[0;32m     12\u001b[0m precip \u001b[38;5;241m=\u001b[39m precip\u001b[38;5;241m.\u001b[39mloc[:, col_subset]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'regions' is not defined"
     ]
    }
   ],
   "source": [
    "# Load precipitation data\n",
    "print(\"Analyzing drought hazard. This process may take few minutes...\")\n",
    "print('\\n')\n",
    "precip = pd.read_csv(os.path.join(workflow_folder, \"drought_hazard.csv\"))\n",
    "# convert timing column to datetime\n",
    "precip['timing'] = pd.to_datetime(precip['timing'], format = '%Y-%m-%d') \n",
    "#'%b-%Y'\n",
    "\n",
    "# column subset based on selected regions\n",
    "col_subset = np.isin(precip.columns, regions)\n",
    "col_subset[0] = True \n",
    "precip = precip.loc[:, col_subset]\n",
    "\n",
    "# print head of the table\n",
    "print('Input precipitation data (top 3 rows): ')\n",
    "print(precip.head(3))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3fae58",
   "metadata": {},
   "source": [
    "### Save hazard indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d954f4a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdH.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# indent=2 is not needed but makes the file human-readable \u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# if the data is nested\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mdump(dH, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>> Drought hazard is save as dH.json.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"dH.json\", 'w') as f:\n",
    "    # indent=2 is not needed but makes the file human-readable \n",
    "    # if the data is nested\n",
    "    json.dump(dH, f, indent=2) \n",
    "\n",
    "print('>>>>> Drought hazard is save as dH.json.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6a645",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "The above workflow calculates the Drought hazard (dH) index that can be used as an input to calculate drought risk in the workflow described in the file Risk_Assessment.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a12200-0053-4e52-945e-844b6ad72543",
   "metadata": {},
   "source": [
    "## Contributors\n",
    "The workflow has beend developed by [Silvia Artuso](https://iiasa.ac.at/staff/silvia-artuso) and [Dor Fridman](https://iiasa.ac.at/staff/dor-fridman) from [IIASA's Water Security Research Group](https://iiasa.ac.at/programs/biodiversity-and-natural-resources-bnr/water-security), and supported by [Michaela Bachmann](https://iiasa.ac.at/staff/michaela-bachmann) from [IIASA's Systemic Risk and Reslience Research Group](https://iiasa.ac.at/programs/advancing-systems-analysis-asa/systemic-risk-and-resilience)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6adf00",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Lyon, B., & Barnston, A. G. (2005). ENSO and the spatial extent of interannual precipitation extremes in tropical land areas. *Journal of climate*, 18(23), 5095-5109.\n",
    "\n",
    "[2] Carrão, H., Singleton, A., Naumann, G., Barbosa, P., & Vogt, J. V. (2014). An optimized system for the classification of meteorological drought intensity with applications in drought frequency analysis. *Journal of Applied Meteorology and Climatology*, 53(8), 1943-1960."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa72d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
