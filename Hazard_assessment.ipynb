{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114c11c0-af34-4523-92fb-9a0d62cd518b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hazard assessment for drought\n",
    "\n",
    "Click [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/CLIMAAX/DROUGHTS/main?labpath=DROUGHTS_notebook_1.ipynb) to launch this workflow on MyBinder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd026bd",
   "metadata": {},
   "source": [
    "### Quantifying drought hazard\n",
    "\n",
    "Hazard indicators Drought hazard (dH) for a given region is estimated as the probability of exceedance of the median of regional (e.g., EU level) severe precipitation deficits for the historical reference period 1979 -2019.\n",
    "The precipitation deficit is calculated using the weighted anomaly of standardized precipitation (WASP) index. This index accounts for precipitation seasonal patterns and is computed by summing weighted and standardized monthly precipitation anomalies $^1$.\n",
    "\n",
    "We use the weighted anomaly of standardized precipitation (WASP) index to define the severity of precipitation deficit. The WASP-index takes into account the annual seasonality of the precipitation cycle and is computed by summing weighted standardized monthly precipitation anomalies (see Eq. 1). Where $P_{n,m}$ is each region's monthly precipitation, $T_m$ is a monthly treshold defining precipitation severity, and $T_A$ is an annual threshold for precipitation severity. The thresholds are defined by dividing multi-annual monthly observed rain using the 'Fisher-jenks' classigication algorithm $^2$. \n",
    "\n",
    "Eq. 1: $$WASP_j = \\Sigma_{P_{n,m} < T_m}^{P_{n,m} >= T_m}( \\frac{P_{n,m} - T_m}{T_m})*\\frac{T_m}{T_A}$$\n",
    "\n",
    "#### Hazard data and methods:\n",
    "\n",
    "This algorithm requires monthly total precipitation for each NUTS2 region during the historical reference period. Usually, these are observation-based or simulated time series of gridded precipitation data. Processing these data is performed by applying Geographic Information System (GIS) techniques, to extract an aggregated value (e.g., total precipitation) of the data points located within each area of interest (e.g., NUTS2 region). Zonal statistics is widely used for that purpose.\n",
    "\n",
    "Point, observation-based datasets are an alternative data source, usually collected by meteorological station networks. One can choose the data collected in one or more (e.g., average) representative stations per area of interest to construct a NUTS2 level dataset. The algorithm expects a table in which each row represnt a month-year combination, and each column an area of interest. The first column represnts the date following this format YYYY-MM-DD. The **title of the first columns has to be 'timing', and the rest of the titles has to be the codes of the areas of interest (e.g., NUTS2), which have to be identical to the codes as they appear in the NUTS2 spatial data from the [European Commision](https://ec.europa.eu/eurostat/en/web/nuts/background)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ccebc",
   "metadata": {},
   "source": [
    "# Workflow implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6c3e8",
   "metadata": {},
   "source": [
    "### Load libraries\n",
    "\n",
    "In this notebook we will use the following Python libraries:\n",
    "- [os](https://docs.python.org/3/library/os.html) - To create directories and work with files\n",
    "- [urllib](https://docs.python.org/3/library/urllib.html) - To access to online resources\n",
    "- [pandas](https://pandas.pydata.org/docs/user_guide/index.html) - To create and manage data frames (tables) in Python\n",
    "- [geopandas](https://geopandas.org/en/stable/docs.html) - Extend pandas to store and manipulate spatial data\n",
    "- [numpy](https://numpy.org/doc/stable/) - For basic math tools and operations\n",
    "- [scipy](https://scipy.org/) - Provide advanced mathematical tools and optimization capacities \n",
    "- [jenkspy](https://github.com/mthh/jenkspy) - To apply Fisher-Jenks alogrithm \n",
    "- [json](https://docs.python.org/3/library/json.html) - To load, store and manipuilate JSON objects\n",
    "- [pyproj](https://pyproj4.github.io/pyproj/stable/) - An interface to a geographic projections and transformations library\n",
    "- [matplotlib](https://matplotlib.org/) - For plotting\n",
    "- [plotly](https://plotly.com/python/) - For dynamic and interactive plotting\n",
    "- [datetime](https://docs.python.org/3/library/datetime.html) - For handling dates in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d06a2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lOAD LIBRARIES\n",
    "import os\n",
    "import urllib\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import jenkspy\n",
    "import json\n",
    "import pyproj\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Function for calculating drought hazard indices\n",
    "%run DROUGHTS_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b9ec1",
   "metadata": {},
   "source": [
    "### Define working environment and global parameters\n",
    "This workflow relies on pre-proceessed data. The user will define the path to the data folder and the code below would create a folder for outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ad5f46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load NUTS2 map with three sample regions\n",
      ">>>>> NUTS2 map has loaded succefully.\n"
     ]
    }
   ],
   "source": [
    "# Set Global Settings\n",
    "\n",
    "workflow_folder = './sample_data/'\n",
    "\n",
    "# debug if folder does not exist - issue an error to check path\n",
    "\n",
    "# create outputs folder\n",
    "if not os.path.exists(os.path.join(workflow_folder, 'outputs')):\n",
    "    os.makedirs(os.path.join(workflow_folder, 'outputs'))\n",
    "\n",
    "# set country = 0 to map all Europe\n",
    "country = 0\n",
    "\n",
    "# alternatively choose one country code (2-digits), e.g. 'IT' for Italy, or more than one to choose several country\n",
    "# e.g., run for North Macedonia and Greece, by setting country = ['MK', 'EL']\n",
    "\n",
    "# Filter countries/locations with missing data (e.g., Liechtenstein, Malta, ..), or very small/remote islands.\n",
    "filterNUTS = ['NO0B', 'LI00', 'MT00', 'FRY2', 'FRY5', 'ES63', 'ES64', 'IS00',\\\n",
    "             'FRY1', 'FRY3', 'FRY4', 'PT20', 'PT30', 'ES70']\n",
    "\n",
    "# Filter non-European countries (+ missing data): Turkey, England\n",
    "filterCNTS = ['UK', 'TR']\n",
    "\n",
    "# load nuts2 spatial data\n",
    "print('Load NUTS2 map with three sample regions')\n",
    "json_nuts_path = 'https://gisco-services.ec.europa.eu/distribution/v2/nuts/geojson/NUTS_RG_01M_2021_4326_LEVL_2.geojson'\n",
    "nuts = load_nuts_json(json_nuts_path)\n",
    "nuts = nuts.query('NUTS_ID not in @filterNUTS')\n",
    "nuts = nuts.query('CNTR_CODE not in @filterCNTS')\n",
    "# Select 3 Polygons in IT to use as an ouput example - TEMPORARY FOR THE DEMO\n",
    "\n",
    "if country == 0:\n",
    "    regions = list(nuts['NUTS_ID'])\n",
    "else:\n",
    "    regions = list(nuts.loc[np.isin(nuts['CNTR_CODE'], country), ]['NUTS_ID'])\n",
    "\n",
    "# define output table \n",
    "nuts = nuts.loc[nuts['NUTS_ID'].isin(regions)]\n",
    "output = pd.DataFrame(regions, columns = ['NUTS_ID'])\n",
    "print('>>>>> NUTS2 map has loaded succefully.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eb7d4d",
   "metadata": {},
   "source": [
    "### Loading precipitation data and calculate hazard indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "636f561d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing drought hazard. This process may take few minutes...\n",
      "\n",
      "\n",
      "Input precipitation data (top 3 rows): \n",
      "      timing      CZ05      CZ06      CZ07      CZ08      DE11      DE12  \\\n",
      "0 1979-01-31  0.000414  0.000407  0.000425  0.000440  0.000234  0.000263   \n",
      "1 1979-02-28  0.000319  0.000359  0.000320  0.000255  0.000327  0.000421   \n",
      "2 1979-03-31  0.000478  0.000545  0.000328  0.000276  0.000525  0.000576   \n",
      "\n",
      "       DE13      DE14      DE21  ...      PL62      PL63      HR05      HR06  \\\n",
      "0  0.000349  0.000310  0.000566  ...  0.000704  0.000558  0.000119  0.000412   \n",
      "1  0.000461  0.000366  0.000443  ...  0.000278  0.000247  0.000102  0.000382   \n",
      "2  0.000502  0.000473  0.001078  ...  0.000752  0.000449  0.000096  0.000285   \n",
      "\n",
      "       NO02      NO06      NO08      NO09      NO0A      NO07  \n",
      "0  0.000549  0.000831  0.000341  0.000918  0.002029  0.002207  \n",
      "1  0.000896  0.002915  0.000246  0.000511  0.002908  0.004564  \n",
      "2  0.001620  0.001493  0.001287  0.002428  0.004047  0.002150  \n",
      "\n",
      "[3 rows x 254 columns]\n",
      "\n",
      "\n",
      ">>>>> Drought hazard is completed.\n",
      "[0.874, 0.773, 0.756, 0.793, 0.754, 0.719, 0.783, 0.722, 0.754, 0.825, 0.787, 0.759, 0.767, 0.743, 0.785, 0.786, 0.821, 0.802, 0.774, 0.883, 0.788, 0.724, 0.752, 0.689, 0.842, 0.795, 0.758, 0.764, 0.798, 0.832, 0.765, 0.783, 0.707, 0.712, 0.817, 0.727, 0.907, 0.786, 0.765, 0.767, 0.789, 0.768, 0.759, 0.716, 0.744, 0.736, 0.703, 0.782, 0.778, 0.731, 0.761, 0.75, 0.864, 0.547, 0.733, 0.83, 0.897, 0.745, 0.79, 0.75, 0.746, 0.713, 0.777, 0.754, 0.783, 0.752, 0.766, 0.812, 0.808, 0.8, 0.794, 0.829, 0.856, 0.746, 0.826, 0.776, 0.619, 0.808, 0.603, 0.767, 0.757, 0.664, 0.718, 0.854, 0.838, 0.842, 0.868, 0.729, 0.7, 0.776, 0.841, 0.821, 0.733, 0.752, 0.815, 0.792, 0.705, 0.783, 0.705, 0.778, 0.786, 0.791, 0.827, 0.855, 0.739, 0.664, 0.744, 0.763, 0.719, 0.739, 0.724, 0.737, 0.664, 0.752, 0.754, 0.802, 0.713, 0.704, 0.779, 0.772, 0.765, 0.741, 0.724, 0.807, 0.8, 0.782, 0.766, 0.738, 0.724, 0.836, 0.708, 0.82, 0.75, 0.752, 0.681, 0.817, 0.836, 0.732, 0.798, 0.842, 0.791, 0.798, 0.784, 0.701, 0.875, 0.821, 0.759, 0.802, 0.86, 0.858, 0.792, 0.785, 0.806, 0.838, 0.769, 0.861, 0.83, 0.898, 0.83, 0.772, 0.89, 0.781, 0.748, 0.818, 0.8, 0.805, 0.835, 0.844, 0.806, 0.766, 0.726, 0.786, 0.762, 0.757, 0.845, 0.786, 0.82, 0.658, 0.72, 0.761, 0.852, 0.733, 0.865, 0.871, 0.935, 0.735, 0.761, 0.775, 0.58, 0.75, 0.829, 0.886, 0.869, 0.812, 0.74, 0.68, 0.848, 0.813, 0.901, 0.868, 0.929, 0.9, 0.802, 0.761, 0.65, 0.87, 0.808, 0.776, 0.791, 0.781, 0.686, 0.817, 0.844, 0.746, 0.763, 0.767, 0.585, 0.672, 0.707, 0.636, 0.868, 0.856, 0.826, 0.78, 0.714, 0.651, 0.715, 0.714, 0.672, 0.733, 0.704, 0.746, 0.805, 0.732, 0.7, 0.838, 0.887, 0.74, 0.737, 0.754, 0.744, 0.848, 0.664, 0.703, 0.707, 0.765, 0.771, 0.571, 0.735, 0.75, 0.767, 0.701, 0.706]\n",
      "[0.874, 0.773, 0.756, 0.793, 0.754, 0.719, 0.783, 0.722, 0.754, 0.825, 0.787, 0.759, 0.767, 0.743, 0.785, 0.786, 0.821, 0.802, 0.774, 0.883, 0.788, 0.724, 0.752, 0.689, 0.842, 0.795, 0.758, 0.764, 0.798, 0.832, 0.765, 0.783, 0.707, 0.712, 0.817, 0.727, 0.907, 0.786, 0.765, 0.767, 0.789, 0.768, 0.759, 0.716, 0.744, 0.736, 0.703, 0.782, 0.778, 0.731, 0.761, 0.75, 0.864, 0.547, 0.733, 0.83, 0.897, 0.745, 0.79, 0.75, 0.746, 0.713, 0.777, 0.754, 0.783, 0.752, 0.766, 0.812, 0.808, 0.8, 0.794, 0.829, 0.856, 0.746, 0.826, 0.776, 0.619, 0.808, 0.603, 0.767, 0.757, 0.664, 0.718, 0.854, 0.838, 0.842, 0.868, 0.729, 0.7, 0.776, 0.841, 0.821, 0.733, 0.752, 0.815, 0.792, 0.705, 0.783, 0.705, 0.778, 0.786, 0.791, 0.827, 0.855, 0.739, 0.664, 0.744, 0.763, 0.719, 0.739, 0.724, 0.737, 0.664, 0.752, 0.754, 0.802, 0.713, 0.704, 0.779, 0.772, 0.765, 0.741, 0.724, 0.807, 0.8, 0.782, 0.766, 0.738, 0.724, 0.836, 0.708, 0.82, 0.75, 0.752, 0.681, 0.817, 0.836, 0.732, 0.798, 0.842, 0.791, 0.798, 0.784, 0.701, 0.875, 0.821, 0.759, 0.802, 0.86, 0.858, 0.792, 0.785, 0.806, 0.838, 0.769, 0.861, 0.83, 0.898, 0.83, 0.772, 0.89, 0.781, 0.748, 0.818, 0.8, 0.805, 0.835, 0.844, 0.806, 0.766, 0.726, 0.786, 0.762, 0.757, 0.845, 0.786, 0.82, 0.658, 0.72, 0.761, 0.852, 0.733, 0.865, 0.871, 0.935, 0.735, 0.761, 0.775, 0.58, 0.75, 0.829, 0.886, 0.869, 0.812, 0.74, 0.68, 0.848, 0.813, 0.901, 0.868, 0.929, 0.9, 0.802, 0.761, 0.65, 0.87, 0.808, 0.776, 0.791, 0.781, 0.686, 0.817, 0.844, 0.746, 0.763, 0.767, 0.585, 0.672, 0.707, 0.636, 0.868, 0.856, 0.826, 0.78, 0.714, 0.651, 0.715, 0.714, 0.672, 0.733, 0.704, 0.746, 0.805, 0.732, 0.7, 0.838, 0.887, 0.74, 0.737, 0.754, 0.744, 0.848, 0.664, 0.703, 0.707, 0.765, 0.771, 0.571, 0.735, 0.75, 0.767, 0.701, 0.706]\n"
     ]
    }
   ],
   "source": [
    "# Load precipitation data\n",
    "print(\"Analyzing drought hazard. This process may take few minutes...\")\n",
    "print('\\n')\n",
    "precip = pd.read_csv(os.path.join(workflow_folder, \"drought_hazard.csv\"))\n",
    "# convert timing column to datetime\n",
    "precip['timing'] = pd.to_datetime(precip['timing'], format = '%Y-%m-%d') \n",
    "#'%b-%Y'\n",
    "\n",
    "# column subset based on selected regions\n",
    "col_subset = np.isin(precip.columns, regions)\n",
    "col_subset[0] = True \n",
    "precip = precip.loc[:, col_subset]\n",
    "\n",
    "# print head of the table\n",
    "print('Input precipitation data (top 3 rows): ')\n",
    "print(precip.head(3))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "## calculate WASP Index (Weighted Anomaly Standardized Precipitation) monthly threshold \n",
    "\n",
    "# empty arrays and tables for intermediate and final results\n",
    "WASP = []\n",
    "WASP_global = []\n",
    "drought_class = precip.copy()\n",
    "\n",
    "# prepare output for drought event index - WASP_j- list of lists wasp = [[rid1], [rid2], ...]\n",
    "for i in range(1, len(precip.columns)):\n",
    "    # For every NUTS2 out of all regions - do the following:\n",
    "    \n",
    "    # empty array for the monthly water deficit thresholds\n",
    "    t_m = []\n",
    "    for mon_ in range(1, 13):\n",
    "        # For every month out of all all months (January, ..., December) - do the following:\n",
    "        \n",
    "        # calculcate monthly dropught threshold -\\\n",
    "            # using a division of the data into to clusters with the Jenks' (Natural breaks) algorithm\n",
    "        r_idx = precip.index[precip.timing.dt.month == mon_].tolist()\n",
    "        t_m_last = jenkspy.jenks_breaks(precip.iloc[r_idx, i], n_classes = 2)[1]\n",
    "        t_m.append(t_m_last)\n",
    "        \n",
    "        # Define every month with water deficity (precipitation < threshold) as a drought month\n",
    "        drought_class.iloc[r_idx, i] = (drought_class.iloc[r_idx, i] < t_m_last).astype(int)\n",
    "\n",
    "    # calculate annual water deficit threshold\n",
    "    t_a = sum(t_m)\n",
    "    \n",
    "    # calculate droughts' magnitude and duration using the WASP indicator\n",
    "    WASP_tmp = []\n",
    "    first_true=0\n",
    "    index = []\n",
    "    for k in range(1, len(precip)):\n",
    "        # for evary row (ordered month-year combinations):\n",
    "            # check if droguht month -> calculate drought accumulated magnitude (over 1+ months)\n",
    "        if drought_class.iloc[k, i]== 1:\n",
    "            # In case of a drought month.\n",
    "            # calculate monthly WASP index\n",
    "            index = drought_class.timing.dt.month[k] - 1\n",
    "            # WASP monthly index: [(precipitation - month_threshold)/month_threshold)]*[month_threshold/annual_treshold]\n",
    "            WASP_last=((precip.iloc[k,i] - t_m[index])/t_m[index])* (t_m[index]/t_a)\n",
    "            \n",
    "            if first_true==0:\n",
    "                # if this is the first month in a drought event:\n",
    "                # append calculated monthly wasp to WASP array.\n",
    "                WASP_tmp.append(WASP_last)\n",
    "                first_true=1\n",
    "            else:\n",
    "                # if this is NOT the first month in a drought event:\n",
    "                # add the calculated monthly wasp to last element in the WASP array (accumulative drought).\n",
    "                WASP_tmp[-1]=WASP_tmp[-1] + WASP_last\n",
    "            WASP_global.append(WASP_last)\n",
    "        else:\n",
    "            # check if not drought month - do not calculate WASP\n",
    "            first_true=0\n",
    "    WASP.append(np.array(WASP_tmp))\n",
    "       \n",
    "\n",
    "# calculate the exceedance probability from the median global WASP as the Hazard index (dH)\n",
    "\n",
    "dH = []\n",
    "WASP = np.array(WASP, dtype=object)\n",
    "\n",
    "# calculate global median deficit severity - \n",
    "    # set drought hazard (dH) as the probability of exceeding the global median water deficit.\n",
    "\n",
    "median_global_wasp = np.nanmedian(WASP_global)\n",
    "\n",
    "\n",
    "# calculate dH per region i\n",
    "for i in range(WASP.shape[0]):\n",
    "    # The more negative the WASP index, the more severe is the deficit event, so \n",
    "    # probability of exceedence the severity is 1 - np.nansum(WASP[i] >= median_global_wasp) / len(WASP[i])\n",
    "    dH.append(round(1 - np.nansum(WASP[i] >= median_global_wasp) / len(WASP[i]), 3))\n",
    "\n",
    "output['hazard_raw'] = dH\n",
    "print('>>>>> Drought hazard is completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3fae58",
   "metadata": {},
   "source": [
    "### Save hazard indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d954f4a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdH.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# indent=2 is not needed but makes the file human-readable \u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# if the data is nested\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mdump(dH, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>> Drought hazard is save as dH.json.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"dH.json\", 'w') as f:\n",
    "    # indent=2 is not needed but makes the file human-readable \n",
    "    # if the data is nested\n",
    "    json.dump(dH, f, indent=2) \n",
    "\n",
    "print('>>>>> Drought hazard is save as dH.json.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6a645",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "The above workflow calculates the Drought hazard (dH) index that can be used as an input to calculate drought risk in the workflow described in the file Risk_Assessment.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a12200-0053-4e52-945e-844b6ad72543",
   "metadata": {},
   "source": [
    "## Contributors\n",
    "The workflow has beend developed by [Silvia Artuso](https://iiasa.ac.at/staff/silvia-artuso) and [Dor Fridman](https://iiasa.ac.at/staff/dor-fridman) from [IIASA's Water Security Research Group](https://iiasa.ac.at/programs/biodiversity-and-natural-resources-bnr/water-security), and supported by [Michaela Bachmann](https://iiasa.ac.at/staff/michaela-bachmann) from [IIASA's Systemic Risk and Reslience Research Group](https://iiasa.ac.at/programs/advancing-systems-analysis-asa/systemic-risk-and-resilience)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6adf00",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Lyon, B., & Barnston, A. G. (2005). ENSO and the spatial extent of interannual precipitation extremes in tropical land areas. *Journal of climate*, 18(23), 5095-5109.\n",
    "\n",
    "[2] Carrão, H., Singleton, A., Naumann, G., Barbosa, P., & Vogt, J. V. (2014). An optimized system for the classification of meteorological drought intensity with applications in drought frequency analysis. *Journal of Applied Meteorology and Climatology*, 53(8), 1943-1960."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa72d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
