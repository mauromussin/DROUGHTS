{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114c11c0-af34-4523-92fb-9a0d62cd518b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Hazard assessment for relative drought\n",
    "\n",
    "- A workflow from the CLIMAAX [Handbook](https://handbook.climaax.eu/) and [DROUGHTS](https://github.com/CLIMAAX/DROUGHTS) GitHub repository.\n",
    "- See our [how to use risk workflows](https://handbook.climaax.eu/notebooks/workflows_how_to.html) page for information on how to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b8a4d-966a-41f5-9e15-421fea4ae651",
   "metadata": {},
   "source": [
    "In this workflow, drought hazard (dH) for a given region is estimated as the probability of exceedance of the median of regional (e.g., EU level) severe precipitation deficits for a historical reference period (e.g. 1981-2015) or for a future projection period (e.g. 2031-2060; 2071-2100). The methodology used here was developed and applied globally by [Carrão et al. (2016)](https://doi.org/10.1016/j.gloenvcha.2016.04.012).\n",
    "\n",
    "A workflow on how to quantify drought risk as the product of drought hazard, exposure and vulnerability can be found in the [risk assessement](Risk_assessment_RELATIVE_DROUGHT.ipynb) notebook. Visualization tools based on preprocessed results for both drought hazard and drought risk can be found in the [risk visualization](Risk_visualization_RELATIVE_DROUGHT.ipynb) notebook.\n",
    " \n",
    "Below is a description of the data and tools used to calculate drought hazard, both for the historic period and for future scenarios, and the outputs of this workflow.\n",
    "\n",
    "\n",
    "![hazard.png](images/hazard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c707b10",
   "metadata": {},
   "source": [
    "## Input files\n",
    "\n",
    "This workflows requires monthly total precipitation for each NUTS3 region during the historical reference period or future projection period in a selected country.\n",
    "\n",
    "Pre-processed data is available for the historic workflow as well as future projections. The ensamble average from ISIMIP 3b bias-adjusted atmospheric climate input data (https://doi.org/10.48364/ISIMIP.842396.1) is used for both historical period (1981 -2015) and future projections (near-future (2050) 2031 -2060 and far-future (2080) 2071 -2100). Precipitation data is the average of five CMIP6 global climate models (GCMs; GFDL-ESM4, IPSL-CM6A-LR, MPI-ESM1-2-HR, MRI-ESM2-0, UKESM1-0-LL), for three SSP-RCPs combinations (SSP126, SSP370, SSP585) provided at a spatial resolution of 0.5°x0.5°.\n",
    "\n",
    ":::{note}\n",
    "The expected data format is a table where each row represents the total precipitation in mm for a month/year combination, and each column represents an area of interest (e.g. NUTS3 region). The first column contains the date in this format DD/MM/YYYY (Other formats shall be specified in the notebook by using the time_format = '%d/%m/%Y' variable). The **title of the first columns has to be 'timing' and the rest of the titles have to be the codes of the areas of interest (e.g. NUTS3), which have to be identical to the codes as they appear in the NUTS3 spatial data from the <a href = \"https://ec.europa.eu/eurostat/en/web/nuts/background\">European Commission</a>**.\n",
    ":::\n",
    "\n",
    "Tables with precipitation data were created for each dataset (historic and future projections) and saved as separate .csv files. Furthermore, for each of the selected SSP-RCPs combinations (SSP126, SSP370, SSP585) we created separate input files for the years 2031 -2060 (near-future) and 2071-2100 (far-future). Users are advised to use the provided data to preserve the consistency between the historical and projected data. Alternatively, users that prefer to use their precipitation data should make sure the historical and projected data are consistent (e.g., outputs of a single model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee36081",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "We use the weighted anomaly of standardized precipitation (WASP) index to define the severity of precipitation deficit. The WASP-index takes into account the annual seasonality of the precipitation cycle and is computed by summing weighted standardized monthly precipitation anomalies (see Eq. 1). Where $P_{n,m}$ is each region's monthly precipitation, $T_m$ is a monthly threshold defining precipitation severity, and $T_A$ is an annual threshold for precipitation severity. The thresholds are defined by dividing multi-annual monthly observed rain using the 'Fisher-jenks' classification algorithm. \n",
    "\n",
    "Eq. 1:\n",
    "\n",
    "$$WASP_j = \\Sigma_{P_{n,m} < T_m}^{P_{n,m} >= T_m}( \\frac{P_{n,m} - T_m}{T_m})*\\frac{T_m}{T_A}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecad8da",
   "metadata": {},
   "source": [
    "## Limitation\n",
    "\n",
    "For future scenarios, model uncertainity is not taken into account as we used an average of 5 different CMIP6 global climate models (GFDL-ESM4, IPSL-CM6A-LR, MPI-ESM1-2-HR, MRI-ESM2-0, UKESM1-0-LL) for each of the three SSP-RCPs combinations (SSP126, SSP370, SSP585). We recommended that users explore model uncertainty on our workflow on their own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e2658-012b-451b-a0a7-08f96287e59a",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "These notebook are designed to work with mauromussin/climaax_image docker image. The container will use \"climaax_floods\" conda environment. Make sure that libraries will be installed in that env.\n",
    "If you need a new lib:  \n",
    "> docker exec -it <container_name> /bin/bash\n",
    "\n",
    "> <containerid> conda activate climaax_floods\n",
    "\n",
    "> <containerid>(climaax_floods) pip install <library>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf6c3e8",
   "metadata": {},
   "source": [
    "## Workflow implementation\n",
    "\n",
    "### Load libraries\n",
    "\n",
    ":::{admonition} Find more info about the libraries used in this workflow here\n",
    ":class: hint dropdown\n",
    "\n",
    "- [os](https://docs.python.org/3/library/os.html) - To create directories and work with files\n",
    "- [pooch](https://www.fatiando.org/pooch/latest/index.html) - To access and download online resources\n",
    "- [pandas](https://pandas.pydata.org/docs/user_guide/index.html) - To create and manage data frames (tables) in Python\n",
    "\n",
    "- [numpy](https://numpy.org/doc/stable/) - For basic math tools and operations\n",
    "- [jenkspy](https://github.com/mthh/jenkspy) - To apply Fisher-Jenks alogrithm \n",
    "- [datetime](https://docs.python.org/3/library/datetime.html) - For handling dates in Python\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4569ddb3-1417-4893-8bb2-e7b3b24b2c91",
   "metadata": {},
   "source": [
    "Verify if env is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "309c15e2-b8d9-4dbd-a071-374e2c67d56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/climaax_floods/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d06a2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pooch\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jenkspy\n",
    "from datetime import date\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f74d96-8e29-40de-9399-b026d8365ebe",
   "metadata": {},
   "source": [
    "inserisco la funzione per il calcolo di WASP in un dataset nc (per sostituzione NUTS3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39d4fc-7df2-4dad-8e5b-5b188f4e6142",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_wasp(nc_file, precip_var='precip', time_dim='time', lat_dim='lat', lon_dim='lon'):\n",
    "    \"\"\"\n",
    "    Calcola l'indice WASP (Weighted Anomaly Standardized Precipitation) da un dataset NetCDF giornaliero.\n",
    "    \n",
    "    Parametri:\n",
    "    - nc_file: percorso del file NetCDF\n",
    "    - precip_var: nome della variabile di precipitazione nel NetCDF\n",
    "    - time_dim: nome della dimensione temporale\n",
    "    - lat_dim: nome della dimensione della latitudine\n",
    "    - lon_dim: nome della dimensione della longitudine\n",
    "    \n",
    "    Output:\n",
    "    - Dataset xarray con WASP calcolato per ogni punto della griglia\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Carica il dataset NetCDF\n",
    "    ds = xr.open_dataset(nc_file)\n",
    "    precip = ds[precip_var]\n",
    "\n",
    "    # 2. Convertire le precipitazioni giornaliere in precipitazioni mensili\n",
    "    precip_monthly = precip.resample({time_dim: '1M'}).sum()\n",
    "\n",
    "    # 3. Calcolare la climatologia mensile (media e deviazione standard)\n",
    "    climatology = precip_monthly.groupby(f\"{time_dim}.month\").mean()\n",
    "    std_dev = precip_monthly.groupby(f\"{time_dim}.month\").std()\n",
    "\n",
    "    # 4. Calcolare le anomalie mensili standardizzate\n",
    "    anomalies = (precip_monthly.groupby(f\"{time_dim}.month\") - climatology) / std_dev\n",
    "\n",
    "    # 5. Calcolare la frazione della precipitazione annuale media per ogni mese\n",
    "    annual_precip = climatology.groupby(\"month\").sum()\n",
    "    weights = climatology / annual_precip\n",
    "\n",
    "    # 6. Calcolare WASP come somma delle anomalie ponderate\n",
    "    wasp = (anomalies * weights).groupby(f\"{time_dim}.year\").sum(dim=\"month\")\n",
    "\n",
    "    return wasp\n",
    "\"\"\"\n",
    "# Esempio di utilizzo\n",
    "nc_file = \"dataset.nc\"  # Sostituire con il percorso corretto del file NetCDF\n",
    "wasp_result = compute_wasp(nc_file)\n",
    "\n",
    "# Mostra i primi valori calcolati\n",
    "print(wasp_result)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b9ec1",
   "metadata": {},
   "source": [
    "### Define working environment and global parameters\n",
    "\n",
    "This workflow relies on pre-processed data. The user will define the path to the data folder and the code below would create a folder for outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad5f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working environment\n",
    "workflow_folder = './sample_data_nuts3/'\n",
    "\n",
    "# Set time format of the 'timing' coloumn\n",
    "time_format = '%d/%m/%Y'\n",
    "\n",
    "\n",
    "# Define scenario 0: historic; 1: SSP1-2.6; 2: SSP3-7.0. 3: SSP5-8.5\n",
    "scn = 0\n",
    "\n",
    "# Define time (applicable only for the future): 0: near-future (2050); 1: far-future (2080)\n",
    "time = 0\n",
    "\n",
    "pattern = \"historic\"\n",
    "pattern_h = \"historic\"\n",
    "if scn != 0:\n",
    "    pattern_h = ['ssp126', 'ssp370', 'ssp585'][scn - 1]\n",
    "    pattern = ['ssp126', 'ssp370', 'ssp585'][scn - 1] + '_' + ['nf', 'ff'][time]\n",
    "\n",
    "# debug if folder does not exist - issue an error to check path\n",
    "\n",
    "# Create outputs folder\n",
    "name_output_folder = 'outputs_hazards'\n",
    "os.makedirs(os.path.join(workflow_folder, name_output_folder), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0481754f-dcaa-48e1-925e-a7a78752903b",
   "metadata": {},
   "source": [
    "### Access to sample dataset\n",
    "\n",
    "Load the file registry for the [`droughtrisk_sample_nuts3` dataset](https://handbook.climaax.eu/resources/datasets/droughtrisk_sample_nuts3.html) in the CLIMAAX cloud storage with pooch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65de35cd-098c-480d-b829-3757fbc5dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_pooch = pooch.create(\n",
    "    path=workflow_folder,\n",
    "    base_url=\"https://object-store.os-api.cci1.ecmwf.int/climaax/droughtrisk_sample_nuts3/\"\n",
    ")\n",
    "sample_data_pooch.load_registry(\"files_registry.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc203b",
   "metadata": {},
   "source": [
    "If any files requested below were downloaded before, pooch will inspect the local file contents and skip the download if the contents match expectations.\n",
    "\n",
    "### Choose country code\n",
    "\n",
    "Choose country code from:  \n",
    "'HR', 'DE', 'BG', 'AT', 'AL', 'BE', 'ES', 'CH', 'CZ', 'EL', 'FR', 'FI', 'EE', 'DK', 'CY', 'HU', 'NL', 'NO', 'LV', 'LT', 'IS', 'MK', 'MT', 'IT', 'TR', 'PL', 'RO', 'SE', 'RS', 'PT', 'IE', 'UK', 'ME', 'LU', 'SK', 'SI' ,'LI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e5b6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccode = \"AL\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eb7d4d",
   "metadata": {},
   "source": [
    "### Load and visualize precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "636f561d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing drought hazard. This process may take few minutes...\n",
      "\n",
      "\n",
      "The following regions are dropped due to missing data: []\n",
      "\n",
      "\n",
      "Input precipitation data (top 3 rows): \n",
      "      timing       AL011       AL012       AL013       AL014       AL015  \\\n",
      "0 1981-01-01   94.509786  103.177409   95.659491  118.158386  145.852112   \n",
      "1 1981-02-01   99.241170  117.427653   94.274695  112.152197  124.374622   \n",
      "2 1981-03-01  120.907837  131.979177  122.187512  142.389905  162.531689   \n",
      "\n",
      "        AL021       AL022       AL031       AL032       AL033       AL034  \\\n",
      "0   95.855312  101.301849  109.709854  110.578285  113.682153   82.214381   \n",
      "1  111.313041  114.888519  131.634750  135.891891  143.291309   87.761983   \n",
      "2  126.032819  127.448021  147.864273  141.353043  168.668628  121.741007   \n",
      "\n",
      "        AL035  \n",
      "0  120.947492  \n",
      "1  154.509487  \n",
      "2  172.366612  \n"
     ]
    }
   ],
   "source": [
    "# Download precipitation data for selected scenario\n",
    "precip_file = sample_data_pooch.fetch(f\"drought_hazard_{pattern_h}.csv\")\n",
    "\n",
    "print(\"Analyzing drought hazard. This process may take few minutes...\")\n",
    "print('\\n')\n",
    "\n",
    "# Load precipitation data\n",
    "precip = pd.read_csv(precip_file)\n",
    "# Convert timing column to datetime\n",
    "precip['timing'] = pd.to_datetime(precip['timing'], format= time_format)\n",
    "#'%b-%Y'\n",
    "\n",
    "# sort precip alphabetical order\n",
    "precip = pd.concat([precip.iloc[:, 0], precip.iloc[:, 1:].reindex(sorted(precip.columns[1:]), axis=1)], axis=1)\n",
    "# sort precip alphabetical order\n",
    "# time  subset\n",
    "\n",
    "if scn != 0:\n",
    "    if time == 0:\n",
    "        precip = precip.loc[(precip['timing'].dt.date >= date(2031,1,1)) & (precip['timing'].dt.date  < date(2060,1,1)), :]\n",
    "    else:\n",
    "        precip = precip.loc[(precip['timing'].dt.date >= date(2071,1,1)) & (precip['timing'].dt.date  < date(2100,1,1)), :]\n",
    "else:\n",
    "    precip = precip.loc[(precip['timing'].dt.date >= date(1981,1,1)) & (precip['timing'].dt.date  < date(2015,1,1)), :]\n",
    "\n",
    "# col_subset aims to extract the relevant results\n",
    "precip = precip.reset_index()\n",
    "\n",
    "col_subset = list(precip.columns.str.contains(ccode))\n",
    "col_subset[1] = True\n",
    "precip = precip.loc[:, col_subset]\n",
    "\n",
    "# clean NaN rows & missing columns\n",
    "precip = precip.loc[~np.array(precip.isna().all(axis = 1)),:]\n",
    "\n",
    "drop_regions = []\n",
    "\n",
    "# missing data in columns\n",
    "col_subset = np.array(precip.isna().all(axis = 0))\n",
    "drop_regions += list(precip.columns[col_subset])\n",
    "precip = precip.loc[:, ~col_subset]\n",
    "\n",
    "regions = precip.columns[1:]\n",
    "output = pd.DataFrame(regions, columns = ['NUTS_ID'])\n",
    "\n",
    "print(\"The following regions are dropped due to missing data: \"+ str(drop_regions))\n",
    "print('\\n')\n",
    "print('Input precipitation data (top 3 rows): ')\n",
    "print(precip.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd605c8",
   "metadata": {},
   "source": [
    "### Calculate WASP Index (Weighted Anomaly Standardized Precipitation) monthly threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34861e1-5bed-4436-99a0-59db70f6723a",
   "metadata": {},
   "source": [
    "This code generates FutureWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27ccf421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_291/83342483.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '81.63686625162761' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  t_m.iloc[mon_ - 1, i - 1] = t_m_last\n",
      "/tmp/ipykernel_291/83342483.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '85.61351521809895' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  t_m.iloc[mon_ - 1, i - 1] = t_m_last\n",
      "/tmp/ipykernel_291/83342483.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '75.28457641601562' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  t_m.iloc[mon_ - 1, i - 1] = t_m_last\n",
      "/tmp/ipykernel_291/83342483.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '97.70197143554688' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  t_m.iloc[mon_ - 1, i - 1] = t_m_last\n",
      "/tmp/ipykernel_291/83342483.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '121.38839111328124' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  t_m.iloc[mon_ - 1, i - 1] = t_m_last\n",
      "/tmp/ipykernel_291/83342483.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '86.80100795200893' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  t_m.iloc[mon_ - 1, i - 1] = t_m_last\n",
      "/tmp/ipykernel_291/83342483.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '83.93621063232422' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  t_m.iloc[mon_ - 1, i - 1] = t_m_last\n",
      "/tmp/ipykernel_291/83342483.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '105.02371215820312' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  t_m.iloc[mon_ - 1, i - 1] = t_m_last\n",
      "/tmp/ipykernel_291/83342483.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '97.70664978027344' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  t_m.iloc[mon_ - 1, i - 1] = t_m_last\n",
      "/tmp/ipykernel_291/83342483.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '123.9494384765625' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  t_m.iloc[mon_ - 1, i - 1] = t_m_last\n",
      "/tmp/ipykernel_291/83342483.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '76.97386678059895' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  t_m.iloc[mon_ - 1, i - 1] = t_m_last\n",
      "/tmp/ipykernel_291/83342483.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '129.91859654017858' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  t_m.iloc[mon_ - 1, i - 1] = t_m_last\n"
     ]
    }
   ],
   "source": [
    "# create empty arrays and tables for intermediate and final results\n",
    "WASP = []\n",
    "WASP_global = []\n",
    "drought_class = precip.copy()\n",
    "\n",
    "\n",
    "t_m = pd.DataFrame(np.tile([0], (12, len(precip.columns) - 1)))\n",
    "    \n",
    "for i in range(1, len(precip.columns)):\n",
    "\n",
    "    # For every NUTS3 out of all regions - do the following:\n",
    "\n",
    "    for mon_ in range(1, 13):\n",
    "        # For every month out of all all months (January, ..., December) - do the following:\n",
    "\n",
    "        # calculate monthly drought threshold -\\\n",
    "            # using a division of the data into to clusters with the Jenks' (Natural breaks) algorithm\n",
    "        r_idx = precip.index[precip.timing.dt.month == mon_].tolist()\n",
    "        \n",
    "        t_m_last = jenkspy.jenks_breaks(precip.iloc[r_idx, i], n_classes = 2)[1]\n",
    "        t_m.iloc[mon_ - 1, i - 1] = t_m_last\n",
    "\n",
    "\n",
    "        # Define every month with water deficity (precipitation < threshold) as a drought month\n",
    "        drought_class.iloc[r_idx, i] = (drought_class.iloc[r_idx, i] < t_m.iloc[mon_ - 1, i - 1]).astype(int)\n",
    "\n",
    "    # calculate annual water deficit threshold\n",
    "    \n",
    "    t_a = list(t_m.sum(axis = 0))\n",
    "\n",
    "    t_m0 = t_m.iloc[:, i - 1]\n",
    "    t_a0 = t_a[i-1]\n",
    "    # calculate droughts' magnitude and duration using the WASP indicator\n",
    "    WASP_tmp = []\n",
    "    first_true=0\n",
    "    index = []\n",
    "    for k in range(1, len(precip)):\n",
    "        # for every row (ordered month-year combinations):\n",
    "            # check if drought month -> calculate drought accumulated magnitude (over 1+ months)\n",
    "        if drought_class.iloc[k, i]== 1:\n",
    "            # In case of a drought month\n",
    "            # calculate monthly WASP index\n",
    "            index = int(drought_class.timing.dt.month[k] - 1)\n",
    "            # WASP monthly index: [(precipitation - month_threshold)/month_threshold)]*[month_threshold/annual_treshold]\n",
    "            WASP_last=((precip.iloc[k,i] - t_m0[index])/t_m0[index])* (t_m0[index]/t_a0)\n",
    "\n",
    "            if first_true==0:\n",
    "                # if this is the first month in a drought event:\n",
    "                # append calculated monthly wasp to WASP array.\n",
    "                WASP_tmp.append(WASP_last)\n",
    "                first_true=1\n",
    "            else:\n",
    "                # if this is NOT the first month in a drought event:\n",
    "                # add the calculated monthly wasp to last element in the WASP array (accumulative drought).\n",
    "                WASP_tmp[-1]=WASP_tmp[-1] + WASP_last\n",
    "            WASP_global.append(WASP_last)\n",
    "        else:\n",
    "            # check if not drought month - do not calculate WASP\n",
    "            first_true=0\n",
    "    WASP.append(np.array(WASP_tmp))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a949e3bc-8e78-405d-858e-b0ac824c09f9",
   "metadata": {},
   "source": [
    "Avoid the FutureWarning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03ac7816-99f6-4c0f-b60f-a43a4cea67a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jenkspy\n",
    "\n",
    "# Create empty arrays and tables for intermediate and final results\n",
    "WASP = []\n",
    "WASP_global = []\n",
    "drought_class = precip.copy()\n",
    "\n",
    "# Initialize t_m as a float64 DataFrame to avoid dtype issues\n",
    "t_m = pd.DataFrame(np.zeros((12, len(precip.columns) - 1)), dtype=np.float64)\n",
    "\n",
    "for i in range(1, len(precip.columns)):\n",
    "    # For every NUTS3 region\n",
    "\n",
    "    for mon_ in range(1, 13):\n",
    "        # For each month (January, ..., December)\n",
    "\n",
    "        # Get indices of rows corresponding to the given month\n",
    "        r_idx = precip.index[precip.timing.dt.month == mon_].tolist()\n",
    "        \n",
    "        # Compute the monthly drought threshold using Jenks' Natural Breaks\n",
    "        t_m_last = jenkspy.jenks_breaks(precip.iloc[r_idx, i], n_classes=2)[1]\n",
    "\n",
    "        # Assign the threshold value (ensuring the dtype remains float64)\n",
    "        t_m.loc[mon_ - 1, i - 1] = t_m_last\n",
    "\n",
    "        # Define drought months (precipitation < threshold)\n",
    "        drought_class.loc[r_idx, i] = (precip.iloc[r_idx, i] < t_m_last).astype(int)\n",
    "\n",
    "    # Calculate annual water deficit threshold\n",
    "    t_a = t_m.sum(axis=0).tolist()\n",
    "\n",
    "    t_m0 = t_m.iloc[:, i - 1]\n",
    "    t_a0 = t_a[i - 1]\n",
    "\n",
    "    # Compute drought magnitude and duration using the WASP indicator\n",
    "    WASP_tmp = []\n",
    "    first_true = False\n",
    "\n",
    "    for k in range(1, len(precip)):\n",
    "        # If the month is classified as drought\n",
    "        if drought_class.iloc[k, i] == 1:\n",
    "            index = int(drought_class.timing.dt.month[k] - 1)\n",
    "            WASP_last = ((precip.iloc[k, i] - t_m0[index]) / t_m0[index]) * (t_m0[index] / t_a0)\n",
    "\n",
    "            if not first_true:\n",
    "                WASP_tmp.append(WASP_last)\n",
    "                first_true = True\n",
    "            else:\n",
    "                WASP_tmp[-1] += WASP_last\n",
    "\n",
    "            WASP_global.append(WASP_last)\n",
    "        else:\n",
    "            first_true = False  # Reset drought event tracking\n",
    "\n",
    "    WASP.append(np.array(WASP_tmp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad44b5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Drought hazard is completed.\n",
      ">>>>> Drought hazard indices were saved.\n"
     ]
    }
   ],
   "source": [
    "dH = []\n",
    "WASP = np.array(WASP, dtype=object)\n",
    "# calculate global median deficit severity -\n",
    "    # set drought hazard (dH) as the probability of exceeding the global median water deficit.\n",
    "\n",
    "median_global_wasp = np.nanmedian(WASP_global)\n",
    "\n",
    "# calculate dH per region i\n",
    "for i in range(WASP.shape[0]):\n",
    "    # The more negative the WASP index, the more severe is the deficit event, so\n",
    "    # probability of exceedence the severity is 1 - np.nansum(WASP[i] >= median_global_wasp) / len(WASP[i])\n",
    "    if len(WASP[i]) > 0:\n",
    "        # set minimum drought hazard as 0.05 to prevent the allocation of 0.0 to the regions with lowest hazard\n",
    "        dH.append(np.maximum(round(1 - np.nansum(WASP[i] >= median_global_wasp) / len(WASP[i]), 3), 0.05))\n",
    "    else:\n",
    "        dH.append(0.05)\n",
    "\n",
    "\n",
    "# https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2004GL020901 - WASP Indicator description\n",
    "\n",
    "output['wasp_raw_mean'] = [np.nan_to_num(np.nanmean(x), 0) for x in WASP]\n",
    "output['wasp_raw_q25'] = [np.nan_to_num(np.nanquantile(x, q = 0.25), 0) for x in WASP]\n",
    "output['wasp_raw_median'] = [np.nan_to_num(np.nanmedian(x), 0) for x in WASP]\n",
    "output['wasp_raw_q75'] = [np.nan_to_num(np.nanquantile(x, q = 0.75), 0) for x in WASP]\n",
    "output['wasp_raw_count'] = [x.shape[0] for x in WASP]\n",
    "\n",
    "output['hazard_raw'] = dH\n",
    "print('>>>>> Drought hazard is completed.')\n",
    "\n",
    "output.to_csv(os.path.join(workflow_folder, name_output_folder, f'droughthazard_{ccode}_{pattern}.csv'),\\\n",
    "              index = False)\n",
    "print('>>>>> Drought hazard indices were saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6a645",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "The above workflow calculates the drought hazard (dH) index that can be used as an input to calculate drought risk in the workflow described in the [risk assessment notebook](Risk_assessment_RELATIVE_DROUGHT.ipynb).\n",
    "\n",
    "Users can use the WASP raw values as a measure of absolute drought hazard for the selected regions. Comparing WASP values of different NUTS3 regions of the selected country will help users understand how drought hazard might change in the future. Examples on how to do this can be found in the visualization workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a12200-0053-4e52-945e-844b6ad72543",
   "metadata": {},
   "source": [
    "## Contributors\n",
    "\n",
    "The workflow has beend developed by [Silvia Artuso](https://iiasa.ac.at/staff/silvia-artuso) and [Dor Fridman](https://iiasa.ac.at/staff/dor-fridman) from [IIASA's Water Security Research Group](https://iiasa.ac.at/programs/biodiversity-and-natural-resources-bnr/water-security), and supported by [Michaela Bachmann](https://iiasa.ac.at/staff/michaela-bachmann) from [IIASA's Systemic Risk and Reslience Research Group](https://iiasa.ac.at/programs/advancing-systems-analysis-asa/systemic-risk-and-resilience)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6adf00",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Carrão, H., Naumann, G., & Barbosa, P. (2016). Mapping global patterns of drought risk: An empirical framework based on sub-national estimates of hazard, exposure and vulnerability. *Global Environmental Change*, 39, 108-124."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
